{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mateus929/cifar10-score-diffusion/blob/main/notebooks/score_based.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuInEfn4ViSL"
      },
      "source": [
        "# Setup\n",
        "\n",
        "This section contains setup code specific to running the notebook on Google Colab. This code depends on the environment and may need to be adjusted based on your specific setup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGiY0BZ-FJN6",
        "outputId": "66d65bc6-8b9c-4f1d-893c-3640804c3067"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Yqv7OYdxFkcc"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "from google.colab import userdata\n",
        "token = userdata.get('GITHUB_TOKEN')\n",
        "user_name = userdata.get('GITHUB_USERNAME')\n",
        "mail = userdata.get('GITHUB_MAIL')\n",
        "\n",
        "!git config --global user.name \"{user_name}\"\n",
        "!git config --global user.email \"{mail}\"\n",
        "!git clone https://{token}@github.com/Mateus929/cifar10-score-diffusion.git\n",
        "\n",
        "%cd cifar10-score-diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xp4ZSZLiI_NH"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "from google.colab import userdata\n",
        "wandb_api_login = userdata.get('WANDB_API_LOGIN')\n",
        "! pip install -r requirements.txt\n",
        "! wandb login {wandb_api_login}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"BASE_WORK_DIR\"] = \"/content/drive/MyDrive/score_diffusion\""
      ],
      "metadata": {
        "id": "4hVbFjxdzbl7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample Run"
      ],
      "metadata": {
        "id": "3BwYZcJ51Zmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "config = {\n",
        "    # Metadata\n",
        "    \"run_name\": \"dsm-cifar10-ve-v1-score-net\",\n",
        "    # \"run_id\": None,\n",
        "\n",
        "    # Training Hyperparameters\n",
        "    \"epochs\": 100,  # Score models need many epochs (often 100-500+)\n",
        "    \"lr\": 2e-4,  # Adam works best with a lower LR for UNets\n",
        "    \"batch_size\": 128,\n",
        "\n",
        "    # Noise Schedule (VE-SDE Specific)\n",
        "    \"sigma_min\": 0.01,  # Small enough to capture fine details\n",
        "    \"sigma_max\": 50.0,  # Large enough to cover the data distribution diameter\n",
        "    \"T\": 1.0,  # Max time horizon\n",
        "\n",
        "    # Sampling / Evaluation (Langevin Dynamics)\n",
        "    \"eval\": True,\n",
        "    \"num_eval_images\": 10000,  # Start small to save time, increase to 10k/50k for final FID\n",
        "    \"n_steps_per_sigma\": 10,  # Higher steps = better quality but slower\n",
        "    \"step_size_factor\": 2e-5,  # Controls the Langevin step magnitude\n",
        "\n",
        "    # Checkpointing\n",
        "    \"save_every\": 5,\n",
        "    \"resume_training\": False,\n",
        "\n",
        "    #Model\n",
        "\n",
        "    \"model_name\": \"score-net\"\n",
        "}\n",
        "\n",
        "from train import train_dsm\n",
        "train_dsm.train_dsm(config)"
      ],
      "metadata": {
        "id": "I13h16Ot1awp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1e462418-1903-4a30-be0b-7d168914a3fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current run id:  ed57facd\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /root/.netrc.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzhorzholianimate\u001b[0m (\u001b[33mMLBeasts\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.24.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/cifar10-score-diffusion/wandb/run-20260124_172753-ed57facd</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/MLBeasts/diffusion-score-matching/runs/ed57facd' target=\"_blank\">dsm-cifar10-ve-v1-score-net</a></strong> to <a href='https://wandb.ai/MLBeasts/diffusion-score-matching' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/MLBeasts/diffusion-score-matching' target=\"_blank\">https://wandb.ai/MLBeasts/diffusion-score-matching</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/MLBeasts/diffusion-score-matching/runs/ed57facd' target=\"_blank\">https://wandb.ai/MLBeasts/diffusion-score-matching/runs/ed57facd</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:19<00:00, 8.67MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training from epoch  0\n",
            "0/100, loss: 69077607564521.086\n",
            "1/100, loss: 75819438093786.03\n",
            "2/100, loss: 74898690632209.02\n",
            "3/100, loss: 69760418713694.28\n",
            "4/100, loss: 66308505812614.875\n",
            "5/100, loss: 65319322740929.8\n",
            "6/100, loss: 67823627360355.516\n",
            "7/100, loss: 68812331508612.914\n",
            "8/100, loss: 68159318449191.28\n",
            "9/100, loss: 62073503190799.06\n",
            "10/100, loss: 65508749594676.375\n",
            "11/100, loss: 55287045204371.31\n",
            "12/100, loss: 68891279179231.266\n",
            "13/100, loss: 80124135093763.92\n",
            "14/100, loss: 71800875852048.38\n",
            "15/100, loss: 65212496176926.77\n",
            "16/100, loss: 65591823229996.52\n",
            "17/100, loss: 67331071144847.38\n",
            "18/100, loss: 68389449703025.92\n",
            "19/100, loss: 64682722367398.95\n",
            "20/100, loss: 66862295839526.63\n",
            "21/100, loss: 60619661642403.68\n",
            "22/100, loss: 73180481036455.61\n",
            "23/100, loss: 65247623232572.234\n",
            "24/100, loss: 67198907384227.03\n",
            "25/100, loss: 60361189388528.94\n",
            "26/100, loss: 66804650652098.45\n",
            "27/100, loss: 66024443283209.82\n",
            "28/100, loss: 78970647581185.31\n",
            "29/100, loss: 67621952963607.57\n",
            "30/100, loss: 67547096224592.53\n",
            "31/100, loss: 58423007431918.32\n",
            "32/100, loss: 59519415171653.4\n",
            "33/100, loss: 66838663939095.57\n",
            "34/100, loss: 63561325375938.45\n",
            "35/100, loss: 62834595252920.63\n",
            "36/100, loss: 73249969300356.9\n",
            "37/100, loss: 65257533216081.84\n",
            "38/100, loss: 81064816248795.33\n",
            "39/100, loss: 62112082563669.12\n",
            "40/100, loss: 78184879756782.98\n",
            "41/100, loss: 68518075641510.305\n",
            "42/100, loss: 71933262935304.52\n",
            "43/100, loss: 66182967259502.65\n",
            "44/100, loss: 62915716153427.805\n",
            "45/100, loss: 63274970635093.77\n",
            "46/100, loss: 59060938562892.6\n",
            "47/100, loss: 64451717002546.414\n",
            "48/100, loss: 61963375538249.33\n",
            "49/100, loss: 69907065782942.445\n",
            "50/100, loss: 67468080464479.59\n",
            "51/100, loss: 58739800751331.84\n",
            "52/100, loss: 64079727920863.92\n",
            "53/100, loss: 69309409993563.01\n",
            "54/100, loss: 66211902789354.39\n",
            "55/100, loss: 67679151059436.36\n",
            "56/100, loss: 61807709095731.73\n",
            "57/100, loss: 57007825473504.57\n",
            "58/100, loss: 74779514675220.95\n",
            "59/100, loss: 73462480290378.64\n",
            "60/100, loss: 70503445349650.98\n",
            "61/100, loss: 71198079069568.98\n",
            "62/100, loss: 62579565574013.055\n",
            "63/100, loss: 79949099906438.22\n",
            "64/100, loss: 69870993412274.086\n",
            "65/100, loss: 77987854283663.39\n",
            "66/100, loss: 75426847460255.1\n",
            "67/100, loss: 59621441611215.55\n",
            "68/100, loss: 66958930687575.734\n",
            "69/100, loss: 71036548261327.55\n",
            "70/100, loss: 65268396380379.99\n",
            "71/100, loss: 64601590119107.11\n",
            "72/100, loss: 70942674221846.92\n",
            "73/100, loss: 81307096140451.69\n",
            "74/100, loss: 56956014845931.05\n",
            "75/100, loss: 72032544815612.08\n",
            "76/100, loss: 77633111983127.58\n",
            "77/100, loss: 65578647737210.44\n",
            "78/100, loss: 70971917971382.67\n",
            "79/100, loss: 73849543906547.56\n",
            "80/100, loss: 57687206075012.26\n",
            "81/100, loss: 58374631414320.45\n",
            "82/100, loss: 61318096650250.48\n",
            "83/100, loss: 80447785744630.17\n",
            "84/100, loss: 67167815740884.79\n",
            "85/100, loss: 66616209983618.945\n",
            "86/100, loss: 63618773579770.766\n",
            "87/100, loss: 71405853151829.11\n",
            "88/100, loss: 70976135932558.73\n",
            "89/100, loss: 82018296775033.12\n",
            "90/100, loss: 70099918842971.664\n",
            "91/100, loss: 76222452263524.83\n",
            "92/100, loss: 61914420024689.266\n",
            "93/100, loss: 69850012996977.266\n",
            "94/100, loss: 86303344599102.86\n",
            "95/100, loss: 70747106404179.16\n",
            "96/100, loss: 61036452516604.73\n",
            "97/100, loss: 65327744143286.67\n",
            "98/100, loss: 69174132129750.09\n",
            "99/100, loss: 71927695731636.05\n",
            "Generating 10000 fake images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [51:24<00:00, 39.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating FID and IS scores...\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 104M/104M [00:00<00:00, 139MB/s] \n",
            "FID/IS Progress: 100%|██████████| 79/79 [00:39<00:00,  1.98it/s]\n",
            "FID/IS Progress: 100%|██████████| 79/79 [00:37<00:00,  2.12it/s]\n",
            "FID/IS Progress: 100%|██████████| 79/79 [00:37<00:00,  2.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: {'FID': 473.00478527262595, 'IS_MEAN': 1.2629188299179077, 'IS_STD': 0.009402861818671227}\n",
            "Test: {'FID': 473.00478527262595, 'IS_MEAN': 1.2629188299179077, 'IS_STD': 0.009402861818671227}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇█████</td></tr><tr><td>epoch/loss</td><td>▆▅▄▃▄▃▁▄▇▅▄▂▃▆▄▃▄▅▃▃▃▃▅▄▃▄▆▆▂▄▃▅▂▂▃▅▄▆█▄</td></tr><tr><td>metrics/fid_test</td><td>▁</td></tr><tr><td>metrics/fid_train</td><td>▁</td></tr><tr><td>metrics/is_test_mean</td><td>▁</td></tr><tr><td>metrics/is_test_std</td><td>▁</td></tr><tr><td>metrics/is_train_mean</td><td>▁</td></tr><tr><td>metrics/is_train_std</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/loss</td><td>71927695731636.05</td></tr><tr><td>metrics/fid_test</td><td>473.00479</td></tr><tr><td>metrics/fid_train</td><td>473.00479</td></tr><tr><td>metrics/is_test_mean</td><td>1.26292</td></tr><tr><td>metrics/is_test_std</td><td>0.0094</td></tr><tr><td>metrics/is_train_mean</td><td>1.26292</td></tr><tr><td>metrics/is_train_std</td><td>0.0094</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dsm-cifar10-ve-v1-score-net</strong> at: <a href='https://wandb.ai/MLBeasts/diffusion-score-matching/runs/ed57facd' target=\"_blank\">https://wandb.ai/MLBeasts/diffusion-score-matching/runs/ed57facd</a><br> View project at: <a href='https://wandb.ai/MLBeasts/diffusion-score-matching' target=\"_blank\">https://wandb.ai/MLBeasts/diffusion-score-matching</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260124_172753-ed57facd/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ScoreNet(\n",
              "  (temb_dense0): Linear(in_features=128, out_features=512, bias=True)\n",
              "  (temb_dense1): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (temb_proj): Linear(in_features=512, out_features=128, bias=True)\n",
              "  (conv1): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "  (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
              "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (gn1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "  (gn2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "  (gn3): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "  (gn4): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "config = {\n",
        "    # Metadata\n",
        "    \"run_name\": \"dsm-cifar10-ve-v2-score-net\",\n",
        "    # \"run_id\": None,\n",
        "\n",
        "    # Training Hyperparameters\n",
        "    \"epochs\": 100,  # Score models need many epochs (often 100-500+)\n",
        "    \"lr\": 2e-4,  # Adam works best with a lower LR for UNets\n",
        "    \"batch_size\": 128,\n",
        "\n",
        "    # Noise Schedule (VE-SDE Specific)\n",
        "    \"sigma_min\": 0.01,  # Small enough to capture fine details\n",
        "    \"sigma_max\": 50.0,  # Large enough to cover the data distribution diameter\n",
        "    \"T\": 1.0,  # Max time horizon\n",
        "\n",
        "    # Sampling / Evaluation (Langevin Dynamics)\n",
        "    \"eval\": True,\n",
        "    \"num_eval_images\": 10000,  # Start small to save time, increase to 10k/50k for final FID\n",
        "    \"n_steps_per_sigma\": 10,  # Higher steps = better quality but slower\n",
        "    \"step_size_factor\": 2e-5,  # Controls the Langevin step magnitude\n",
        "\n",
        "    # Checkpointing\n",
        "    \"save_every\": 5,\n",
        "    \"resume_training\": False,\n",
        "\n",
        "    #Model\n",
        "\n",
        "    \"model_name\": \"score-net\"\n",
        "}\n",
        "\n",
        "from train import train_dsm\n",
        "train_dsm.train_dsm(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b4bQd4SClCex",
        "outputId": "b411beb0-6abe-42a6-da64-21e9b9475f25"
      },
      "execution_count": 5,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NEW TRAINING\n",
            "Current run id:  71698bcc\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /root/.netrc.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzhorzholianimate\u001b[0m (\u001b[33mMLBeasts\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.24.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/cifar10-score-diffusion/wandb/run-20260124_200054-71698bcc</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/MLBeasts/diffusion-score-matching/runs/71698bcc' target=\"_blank\">dsm-cifar10-ve-v2-score-net</a></strong> to <a href='https://wandb.ai/MLBeasts/diffusion-score-matching' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/MLBeasts/diffusion-score-matching' target=\"_blank\">https://wandb.ai/MLBeasts/diffusion-score-matching</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/MLBeasts/diffusion-score-matching/runs/71698bcc' target=\"_blank\">https://wandb.ai/MLBeasts/diffusion-score-matching/runs/71698bcc</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training from epoch  0\n",
            "0/100, loss: 9862.413376908167\n",
            "1/100, loss: 2383.6670621203643\n",
            "2/100, loss: 1772.8209319053708\n",
            "3/100, loss: 1522.7114685526894\n",
            "4/100, loss: 1446.8378500389626\n",
            "5/100, loss: 1423.5253253751398\n",
            "6/100, loss: 1291.8609210158247\n",
            "7/100, loss: 1443.7324968030691\n",
            "8/100, loss: 1203.6018487876638\n",
            "9/100, loss: 1161.0248108690657\n",
            "10/100, loss: 1035.9200603358277\n",
            "11/100, loss: 974.7092895507812\n",
            "12/100, loss: 884.7487177934183\n",
            "13/100, loss: 863.8934958377457\n",
            "14/100, loss: 732.7756549025436\n",
            "15/100, loss: 756.3744873671276\n",
            "16/100, loss: 735.7665642545657\n",
            "17/100, loss: 668.7417248191736\n",
            "18/100, loss: 696.1197050831202\n",
            "19/100, loss: 643.2978337670836\n",
            "20/100, loss: 621.6060270421646\n",
            "21/100, loss: 650.2786811379825\n",
            "22/100, loss: 600.340513263517\n",
            "23/100, loss: 743.8936936946781\n",
            "24/100, loss: 561.2093146048543\n",
            "25/100, loss: 555.5110554804887\n",
            "26/100, loss: 563.6821922829084\n",
            "27/100, loss: 580.1343723306875\n",
            "28/100, loss: 512.3329709728661\n",
            "29/100, loss: 564.3434240628997\n",
            "30/100, loss: 490.7300856021969\n",
            "31/100, loss: 484.78167677779334\n",
            "32/100, loss: 475.899042934408\n",
            "33/100, loss: 457.8092389899447\n",
            "34/100, loss: 463.18467778744906\n",
            "35/100, loss: 442.33436853745405\n",
            "36/100, loss: 433.02227127582523\n",
            "37/100, loss: 406.0938506845928\n",
            "38/100, loss: 404.1876489975873\n",
            "39/100, loss: 391.0994076936141\n",
            "40/100, loss: 379.95707784589297\n",
            "41/100, loss: 382.5794296069523\n",
            "42/100, loss: 363.3583155483236\n",
            "43/100, loss: 351.91546814277046\n",
            "44/100, loss: 357.4006818298184\n",
            "45/100, loss: 333.8960046402329\n",
            "46/100, loss: 341.2256041621918\n",
            "47/100, loss: 327.54516219117147\n",
            "48/100, loss: 325.91131919607176\n",
            "49/100, loss: 315.88597922556846\n",
            "50/100, loss: 331.76274830849883\n",
            "51/100, loss: 302.99924236795175\n",
            "52/100, loss: 327.0964558398937\n",
            "53/100, loss: 295.2588804591342\n",
            "54/100, loss: 306.9129884919852\n",
            "55/100, loss: 299.6330126594095\n",
            "56/100, loss: 322.19675072867545\n",
            "57/100, loss: 309.6668509168698\n",
            "58/100, loss: 290.63470857039744\n",
            "59/100, loss: 290.8907306797974\n",
            "60/100, loss: 289.26163722669986\n",
            "61/100, loss: 288.0345947187575\n",
            "62/100, loss: 291.4645541452081\n",
            "63/100, loss: 290.3631605845888\n",
            "64/100, loss: 282.1091792894446\n",
            "65/100, loss: 291.6836099063649\n",
            "66/100, loss: 278.2926283736363\n",
            "67/100, loss: 289.0479874086502\n",
            "68/100, loss: 274.5166379728586\n",
            "69/100, loss: 275.2761281591547\n",
            "70/100, loss: 277.603905172909\n",
            "71/100, loss: 281.8972142992727\n",
            "72/100, loss: 297.7264049559298\n",
            "73/100, loss: 270.1479617067615\n",
            "74/100, loss: 273.59689428617276\n",
            "75/100, loss: 268.242986147361\n",
            "76/100, loss: 273.76532919022736\n",
            "77/100, loss: 269.2426552931061\n",
            "78/100, loss: 266.73462507243045\n",
            "79/100, loss: 370.91912634964183\n",
            "80/100, loss: 265.78707222316575\n",
            "81/100, loss: 265.21634695536034\n",
            "82/100, loss: 263.48736057135153\n",
            "83/100, loss: 263.1897499103985\n",
            "84/100, loss: 275.0215376441741\n",
            "85/100, loss: 261.44746110140517\n",
            "86/100, loss: 264.29535345287275\n",
            "87/100, loss: 266.7625997011619\n",
            "88/100, loss: 272.32528994821223\n",
            "89/100, loss: 264.5144006285216\n",
            "90/100, loss: 264.7144773049123\n",
            "91/100, loss: 263.90753142608094\n",
            "92/100, loss: 263.11226609173946\n",
            "93/100, loss: 258.2965764194498\n",
            "94/100, loss: 272.6784735482062\n",
            "95/100, loss: 259.0446453045701\n",
            "96/100, loss: 260.8817420822885\n",
            "97/100, loss: 261.0387454606078\n",
            "98/100, loss: 275.7396420530041\n",
            "99/100, loss: 258.094448782294\n",
            "Generating 10000 fake images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [51:23<00:00, 39.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating FID and IS scores...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FID/IS Progress: 100%|██████████| 79/79 [00:39<00:00,  1.99it/s]\n",
            "FID/IS Progress: 100%|██████████| 79/79 [00:37<00:00,  2.11it/s]\n",
            "FID/IS Progress: 100%|██████████| 391/391 [03:19<00:00,  1.96it/s]\n",
            "FID/IS Progress: 100%|██████████| 79/79 [00:37<00:00,  2.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: {'FID': 497.37125100120664, 'IS_MEAN': 1.2519344091415405, 'IS_STD': 0.007916275411844254}\n",
            "Test: {'FID': 497.29765009211013, 'IS_MEAN': 1.2519344091415405, 'IS_STD': 0.007916275411844254}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇████</td></tr><tr><td>epoch/loss</td><td>██▇█▆▄▄▄▃▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/fid_test</td><td>▁</td></tr><tr><td>metrics/fid_train</td><td>▁</td></tr><tr><td>metrics/is_test_mean</td><td>▁</td></tr><tr><td>metrics/is_test_std</td><td>▁</td></tr><tr><td>metrics/is_train_mean</td><td>▁</td></tr><tr><td>metrics/is_train_std</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/loss</td><td>258.09445</td></tr><tr><td>metrics/fid_test</td><td>497.29765</td></tr><tr><td>metrics/fid_train</td><td>497.37125</td></tr><tr><td>metrics/is_test_mean</td><td>1.25193</td></tr><tr><td>metrics/is_test_std</td><td>0.00792</td></tr><tr><td>metrics/is_train_mean</td><td>1.25193</td></tr><tr><td>metrics/is_train_std</td><td>0.00792</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dsm-cifar10-ve-v2-score-net</strong> at: <a href='https://wandb.ai/MLBeasts/diffusion-score-matching/runs/71698bcc' target=\"_blank\">https://wandb.ai/MLBeasts/diffusion-score-matching/runs/71698bcc</a><br> View project at: <a href='https://wandb.ai/MLBeasts/diffusion-score-matching' target=\"_blank\">https://wandb.ai/MLBeasts/diffusion-score-matching</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260124_200054-71698bcc/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ScoreNet(\n",
              "  (temb_dense0): Linear(in_features=128, out_features=512, bias=True)\n",
              "  (temb_dense1): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (temb_proj): Linear(in_features=512, out_features=128, bias=True)\n",
              "  (conv1): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "  (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
              "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (gn1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "  (gn2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "  (gn3): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "  (gn4): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}